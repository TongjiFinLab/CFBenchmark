<div style="text-align:center">
<!-- <img src="https://big-cheng.com/k2/k2.png" alt="k2-logo" width="200"/> -->
<h2>ğŸ“ˆ CFBenchmark: Chinese Financial Assistant with Large Language Model</h2>
</div>

<div align="center">

<a href='https://arxiv.org/abs/2311.05812'><img src='https://img.shields.io/badge/Paper-ArXiv-C71585'></a> 
<a href='https://huggingface.co/datasets/TongjiFinLab/CFBenchmark'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging Face-CFBenchmark-red'></a> 
![license](https://img.shields.io/badge/License-Apache--2.0-blue.svg)

[English](README.md) | ç®€ä½“ä¸­æ–‡

</div>

# ç®€ä»‹

æ¬¢è¿æ¥åˆ°**CFBenchmark**

è¿‘å¹´æ¥ï¼Œéšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†ä¼˜å¼‚çš„è¡¨ç°ã€‚ ç„¶è€Œï¼Œæˆ‘ä»¬æ³¨æ„åˆ°ï¼Œç›®å‰ä¸“æ³¨äºå¤§è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸè¡¨ç°çš„åŸºå‡†æµ‹è¯•æ•°é‡æœ‰é™ã€‚

â€œä¹¦ç”Ÿâ€¢æµä¸–â€ä¸­æ–‡é‡‘èè¯„æµ‹åŸºå‡†ï¼ˆCFBenchmarkï¼‰åŸºç¡€ç‰ˆæœ¬ç”±[CFBenchmark-Basic](https://huggingface.co/datasets/TongjiFinLab/CFBenchmark)å’Œ[CFBenchmark-OpenFinData](https://github.com/open-compass/OpenFinData)ä¸¤éƒ¨åˆ†æ•°æ®ç»„æˆï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ æ–¹é¢ï¼Œæ¥è¯„æµ‹ç›¸å…³å¤§æ¨¡å‹åœ¨é‡‘èå®é™…åº”ç”¨ä¸­çš„å„é¡¹èƒ½åŠ›å’Œå®‰å…¨æ€§ï¼š
* é‡‘èè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œä¸»è¦å…³æ³¨æ¨¡å‹å¯¹é‡‘èæ–‡æœ¬çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œå¦‚é‡‘èå®ä½“è¯†åˆ«ï¼Œè¡Œä¸šåˆ†ç±»ï¼Œç ”æŠ¥æ€»ç»“å’Œé£é™©è¯„ä¼°ï¼›
* é‡‘èåœºæ™¯è®¡ç®—ï¼Œä¾§é‡äºè¯„ä¼°æ¨¡å‹åœ¨ç‰¹å®šé‡‘èåœºæ™¯ä¸‹çš„è®¡ç®—å’Œæ¨ç†èƒ½åŠ›ï¼Œå¦‚é£é™©è¯„ä¼°å’ŒæŠ•èµ„ç»„åˆä¼˜åŒ–ï¼›
* é‡‘èåˆ†æä¸è§£è¯»ä»»åŠ¡ï¼Œæ£€éªŒæ¨¡å‹åœ¨ç†è§£å¤æ‚é‡‘èæŠ¥å‘Šã€é¢„æµ‹å¸‚åœºè¶‹åŠ¿å’Œè¾…åŠ©å†³ç­–åˆ¶å®šæ–¹é¢çš„èƒ½åŠ›ï¼›
* é‡‘èåˆè§„ä¸å®‰å…¨æ£€æŸ¥ï¼Œè¯„ä¼°æ¨¡å‹æ½œåœ¨çš„åˆè§„é£é™©ï¼Œå¦‚ç”Ÿæˆå†…å®¹çš„éšç§æ€§ã€å†…å®¹å®‰å…¨æ€§ã€é‡‘èåˆè§„æ€§ç­‰æ–¹é¢çš„èƒ½åŠ›ã€‚

æœªæ¥ï¼Œâ€œä¹¦ç”Ÿâ€¢æµä¸–â€ä¸­æ–‡é‡‘èè¯„æµ‹åŸºå‡†å°†ç»§ç»­æ·±åŒ–é‡‘èå¤§æ¨¡å‹è¯„æµ‹ä½“ç³»å»ºè®¾ï¼ŒåŒ…æ‹¬å¤§æ¨¡å‹åœ¨é‡‘èè¡Œä¸šåº”ç”¨è¿‡ç¨‹ä¸­çš„æ¨¡å‹ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ã€åŠæ—¶æ€§ã€å®‰å…¨æ€§ã€éšç§æ€§ã€åˆè§„æ€§ç­‰èƒ½åŠ›è¯„ä¼°ã€‚

<div align="center">
  <img src="imgs/Framework.png" width="100%"/>
  <br />
  <br /></div>

# æ›´æ–°

\[2024.03.17\] å¢åŠ äº†åœ¨é‡‘èæ•°æ®é›†[CFBenchmark-OpenFinData](https://github.com/open-compass/OpenFinData)ä¸Šçš„è¯„æµ‹å†…å®¹ï¼Œæä¾›äº†è¯¥æ•°æ®é›†ä¸­å¯¹åº”ä¸»è§‚é¢˜çš„ä¸€ç§è¯„æµ‹ä»£ç å®ç°æ–¹å¼ï¼Œå¹¶æµ‹è¯•äº†9ä¸ªå¤§æ¨¡å‹åœ¨[OpenFinData](https://github.com/open-compass/OpenFinData) æ•°æ®é›†ä¸Šçš„è¯„æµ‹ç»“æœã€‚

>  [OpenFinData](https://github.com/open-compass/OpenFinData)æ•°æ®æ¥æºäºä¸œæ–¹è´¢å¯Œä¸ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤è”åˆå‘å¸ƒçš„å¼€æºé¡¹ç›®ï¼Œæ›´å¤šè¯¦æƒ…ï¼š[Githubåœ°å€](https://github.com/open-compass/opencompass/blob/main/configs/datasets/OpenFinData/OpenFinData.md)ã€‚

\[2023.11.10\] æˆ‘ä»¬å‘å¸ƒäº†[CFBenchmark-Basic](https://huggingface.co/datasets/TongjiFinLab/CFBenchmark)å’Œå¯¹åº”çš„[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2311.05812)ï¼Œä¸»è¦é’ˆå¯¹å¤§æ¨¡å‹åœ¨é‡‘èè‡ªç„¶è¯­è¨€ä»»åŠ¡å’Œé‡‘èæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šçš„èƒ½åŠ›è¿›è¡Œå…¨é¢è¯„æµ‹ã€‚

# ç›®å½•

- [CFBenchmark-Basic](#cfbenchmark-basic)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æµ‹è¯•ç»“æœ](#æµ‹è¯•ç»“æœ)
- [è‡´è°¢](#è‡´è°¢)
- [æœªæ¥çš„å·¥ä½œ](#æœªæ¥çš„å·¥ä½œ)
- [è®¸å¯è¯](#è®¸å¯è¯)
- [å¼•ç”¨](#å¼•ç”¨)

# CFBenchmark-Basic

CFBenchmarkçš„åŸºç¡€ç‰ˆæœ¬åŒ…æ‹¬3917ä¸ªé‡‘èæ–‡æœ¬æ¶µç›–ä¸‰ä¸ªæ–¹é¢å’Œå…«ä¸ªä»»åŠ¡ï¼Œä»é‡‘èè¯†åˆ«ã€é‡‘èåˆ†ç±»ã€é‡‘èç”Ÿæˆä¸‰ä¸ªæ–¹é¢è¿›è¡Œç»„ç»‡ã€‚
* è¯†åˆ«-å…¬å¸ï¼šè¯†åˆ«ä¸è´¢åŠ¡æ–‡ä»¶ç›¸å…³çš„å…¬å¸åç§°ï¼Œå…±273ä¸ªã€‚
* è¯†åˆ«-äº§å“ï¼šè¯†åˆ«ä¸è´¢åŠ¡æ–‡ä»¶ç›¸å…³çš„äº§å“åç§°ï¼Œå…±297ä¸ªã€‚
* åˆ†ç±»-æƒ…æ„Ÿåˆ†æï¼šå¯¹äºè´¢åŠ¡æ–‡ä»¶ç›¸å…³çš„æƒ…æ„Ÿç±»åˆ«è¿›è¡Œåˆ†ç±»ï¼Œå…±591ä¸ªã€‚
* åˆ†ç±»-äº‹ä»¶æ£€æµ‹ï¼šå¯¹äºè´¢åŠ¡æ–‡ä»¶ç›¸å…³çš„äº‹ä»¶ç±»åˆ«è¿›è¡Œåˆ†ç±»ï¼Œå…±577ä¸ªã€‚
* åˆ†ç±»-è¡Œä¸šç¡®è®¤ï¼šå¯¹äºè´¢åŠ¡æ–‡ä»¶ç›¸å…³çš„äºŒçº§è¡Œä¸šè¿›è¡Œåˆ†ç±»ï¼Œå…±402ä¸ªã€‚
* ç”Ÿæˆ-æŠ•èµ„å»ºè®®ï¼šåŸºäºæä¾›çš„è´¢åŠ¡æ–‡ä»¶ç”ŸæˆæŠ•èµ„å»ºè®®ï¼Œå…±593ä¸ªã€‚
* ç”Ÿæˆ-é£é™©æç¤ºï¼šåŸºäºæä¾›çš„è´¢åŠ¡æ–‡ä»¶ç”ŸæˆæŠ•èµ„å»ºè®®ï¼Œå…±591ä¸ªã€‚
* ç”Ÿæˆ-å†…å®¹æ€»ç»“ï¼šåŸºäºæä¾›çš„è´¢åŠ¡æ–‡ä»¶ç”ŸæˆæŠ•èµ„å»ºè®®ï¼Œå…±593ä¸ªã€‚

æˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªæ¨¡å‹ï¼Œå±•ç¤ºäº†é›¶æ ·æœ¬ï¼ˆZero-shotï¼‰å’Œå°‘æ ·æœ¬ï¼ˆFew-shotï¼‰æ˜¯å¦‚ä½•è¿›è¡Œæµ‹è¯•çš„ã€‚

æ ·ä¾‹1 å°‘æ ·æœ¬ï¼ˆFew-shotï¼‰çš„è¾“å…¥ï¼š
<div align="center">
  <img src="imgs/fewshot.png" width="100%"/>
  <br />
  <br /></div>

æ ·ä¾‹2 é›¶æ ·æœ¬ï¼ˆZero-shotï¼‰çš„è¾“å…¥ï¼š
<div align="center">
  <img src="imgs/zeroshot.png" width="100%"/>
  <br />
  <br /></div>

# å¿«é€Ÿå¼€å§‹

## å®‰è£…

ä»¥ä¸‹å±•ç¤ºäº†ä¸€ä¸ªå®‰è£…çš„ç®€å•æ­¥éª¤ã€‚
 ```python
    conda create --name CFBenchmark python=3.10
    conda activate CFBenchmark
 ```

```python
    git clone https://github.com/TongjiFinLab/CFBenchmark
    cd CFBenchmark
    pip install -r requirements.txt
```

## æµ‹è¯„

### CFBenchmark-Basic

æˆ‘ä»¬åœ¨ ```CFBenchmark-Basic/src``` ä¸­ä¸ºæ‚¨å‡†å¤‡äº†æµ‹è¯•å’Œè¯„ä¼°ä»£ç ã€‚

ä¸ºäº†è¿è¡Œæµ‹è¯„ï¼Œæ‚¨å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

```cmd
cd CFBenchmark-Basic/src
python -m run.py
```

æ‚¨å¯ä»¥è¿›å…¥```CFBenchmark-Basic/src/run.py```æ¥ä¿®æ”¹å…¶ä¸­çš„å‚æ•°ï¼Œè®©ä»£ç è¿è¡Œçš„è·¯å¾„ç¬¦åˆæ‚¨çš„è¦æ±‚ã€‚

```py
from CFBenchmark import CFBenchmark
if __name__=='__main__':

    # EXPERIMENT SETUP
    modelname = 'YOUR-MODEL-NAME'
    model_type= 'NORMAL' #NORMAL or LoRA
    model_path= 'YOUR-MODEL-PATH'
    peft_model_path= ''#PASS YOUR OWN PATH OF PEFT MODEL IF NEEDED
    fewshot_text_path= '../fewshot'#DEFAULT PATH
    test_type='few-shot'#LET'S TAKE THE FEW-SHOT TEST AS AN EXAMPLE
    response_path='../cfbenchmark-response'#PATH TO RESERVE THE RESPONSE OF YOUR MODEL
    scores_path='../cfbenchmark-scores'	#PATH TO RESERVE THE SCORE OF YOUR MODEL
    embedding_model_path='../bge-zh-v1.5' #PASS YOUR OWN PATH OF BGE-ZH-V1.5
    benchmark_path='../data' #DEFAULT PATH

    #generate Class CFBenchmark
    cfb=CFBenchmark(
        model_name=modelname,
        model_type=model_type,
        model_path=model_path,
        peft_model_path=peft_model_path,
        fewshot_text_path=fewshot_text_path,
        test_type=test_type,
        response_path=response_path,
        scores_path=scores_path,
        embedding_model_path=embedding_model_path,
        benchmark_path=benchmark_path,
    )
    
    cfb.generate_model()# TO GET RESPONSE FROM YOUR MODEL
    cfb.get_test_scores()# TO GET YOUR MODEL SCORES FROM RESPONSE
```

æˆ‘ä»¬åœ¨```codes/CFBenchmark.py```ä¸­å®šä¹‰äº†ä¸€ä¸ªç±»â€œCFBenchmarkâ€æ¥è¿›è¡Œè¯„ä¼°ã€‚

```Py
class CFBenchmark:
    def __init__(self,
                 model_name,
                 model_type,
                 model_path,
                 peft_model_path,
                 fewshot_text_path,
                 test_type,
                 response_path,
                 scores_path,
                 embedding_model_path,
                 benchmark_path
                 ) -> None:
```

* æ‚¨å¯ä»¥ä½¿ç”¨å‚æ•°æ¥è®¾ç½®æ¨¡å‹çš„è·¯å¾„ã€‚ å¦‚æœä½ æƒ³ä½¿ç”¨è¿›è¡ŒLoRAå¾®è°ƒåçš„æ¨¡å‹ï¼Œè¯·å°†``model_type``è®¾ç½®ä¸º````LoRA````å¹¶é€šè¿‡````peft_model_path```ä¼ é€’ä½ çš„peftæ¨¡å‹è·¯å¾„ã€‚
* æ‚¨å¯ä»¥å°†``test-type``è®¾ç½®ä¸º'zero-shot'æˆ–'few-shot'æ¥è¿›è¡Œä¸åŒçš„è¯„ä¼°ã€‚
* ä¸ºâ€œbzh-zh-v1.5â€è®¾ç½®â€œembedding_model_pathâ€ï¼Œç”¨äºè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ã€‚
* æ‚¨å¯ä»¥ä¿®æ”¹â€œCFBenchmark.generate_model()â€ä¸­çš„è¶…å‚æ•°æ¥ç”Ÿæˆæ–‡æœ¬ã€‚
* æˆ‘ä»¬åœ¨Hugging Faceå’ŒGithubä¸­éƒ½æä¾›äº†ä¿å­˜ä¸ºDatasetæ•°æ®ç±»å‹çš„CFBenchmarkã€‚

### CFBenchmark-OpenFinData

æˆ‘ä»¬åœ¨```CFBenchmark-OpenFinData``` ä¸­ä¸ºæ‚¨å‡†å¤‡äº†æµ‹è¯•å’Œè¯„ä¼°çš„ä»£ç ä¸æ•°æ®ã€‚
è¯„æµ‹ä»£ç çš„è®¾è®¡ä¸Fineva1.0ç›¸ä¼¼ï¼Œé€šè¿‡```CFBenchmark-OpenFinData/src/evaluator```å¯¹äºè¯„æµ‹æ¨¡å‹çš„è°ƒç”¨æ–¹å¼è¿›è¡Œå®šä¹‰ï¼Œå¹¶é€šè¿‡```CFBenchmark-OpenFinData/run_scripts```ä¸­çš„bashæ–‡ä»¶å¯¹äºå…³é”®å‚æ•°è¿›è¡Œé…ç½®å’Œå®éªŒã€‚

ä¸ºäº†è¿è¡Œæµ‹è¯„ï¼Œæ‚¨å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

```cmd
cd CFBenchmark-OpenFinData/run_scripts
sh run_baichuan2_7b.sh
```

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå› ä¸ºOpenFinDataçš„è¯„æµ‹è¿‡ç¨‹æ¶‰åŠä¸»è§‚é¢˜çš„åˆ¤æ–­ï¼Œå› æ­¤æˆ‘ä»¬çš„è¯„æµ‹æ¡†æ¶å€ŸåŠ©äº†æ–‡å¿ƒä¸€è¨€æ¥å¯¹é‡‘èè§£è¯»ä¸åˆ†æç±»é—®é¢˜å’Œé‡‘èåˆè§„ç±»é—®é¢˜è¿›è¡Œè¯„æµ‹ã€‚ä¸ºäº†é¡ºåˆ©è¯•ç”¨æ–‡å¿ƒä¸€è¨€çš„APIå‚ä¸è¯„æµ‹ï¼Œè¯·æ‚¨åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®```BAIDU_API_KEY```å’Œ```BAIDU_SECRET_KEY```ï¼Œä»¥ä¾¿äº```CFBenchmark-OpenFinData/src/get_score.py```çš„```get_access_token```å‡½æ•°å¯ä»¥é¡ºåˆ©è¿è¡Œã€‚

```Py
def get_access_token():
    """
    ä½¿ç”¨ API Keyï¼ŒSecret Key è·å–access_tokenï¼Œæ›¿æ¢ä¸‹åˆ—ç¤ºä¾‹ä¸­çš„åº”ç”¨API Keyã€åº”ç”¨Secret Key
    """

    url = "https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={}&client_secret={}".format(os.environ.get("BAIDU_API_KEY"), os.environ.get("BAIDU_SECRET_KEY"))
    
    payload = json.dumps("")
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json'
    }
    
    response = requests.request("POST", url, headers=headers, data=payload)
    return response.json().get("access_token")
```


# æµ‹è¯•ç»“æœ

æˆ‘ä»¬ä½¿ç”¨ä¸¤ç§ç±»å‹çš„æŒ‡æ ‡æ¥è¯„ä¼°é‡‘èé¢†åŸŸå¤§è¯­è¨€æ¨¡å‹åœ¨ CFBenchmark ä¸Šçš„è¡¨ç°ã€‚
å¯¹äºCFBenchmark-Basicä¸­çš„è¯†åˆ«å’Œåˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬é‡‡ç”¨ **F1_score** ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œå¹³è¡¡äº†ç²¾åº¦å’Œå¬å›ç‡ã€‚ 

å¯¹äºCFBenchmark-Basicä¸­çš„ç”Ÿæˆä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ©ç”¨åœ°é¢å®å†µçš„å‘é‡ï¼ˆé€šè¿‡**bge-zh-v1.5**ç”Ÿæˆï¼‰è¡¨ç¤ºå’Œç”Ÿæˆçš„ç­”æ¡ˆä¹‹é—´çš„**ä½™å¼¦ç›¸ä¼¼åº¦**æ¥è¡¡é‡ç”Ÿæˆèƒ½åŠ›ã€‚ 

å¯¹äºCFBenchmark-OpenFinDataä¸­çš„knowledge, calculation, å’Œidentificationä»»åŠ¡ï¼Œæˆ‘ä»¬ç›´æ¥è®¡ç®—å¤šé¡¹é€‰æ‹©é¢˜çš„å‡†ç¡®ç‡è¿›è¡Œæ¨¡å‹æ•ˆæœè¯„ä¼°ã€‚

å¯¹äºCFBenchmark-OpenFinDataä¸­çš„explanation, analysis, å’Œcomplianceä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ©ç”¨æ–‡å¿ƒä¸€è¨€4ä½œä¸ºæ‰“åˆ†å™¨ï¼Œæ¥åˆ¤æ–­æ¨¡å‹ç”Ÿæˆç»“æœå’ŒçœŸå®ç­”æ¡ˆä¹‹é—´çš„æ­£ç¡®æ€§ã€‚

å¤§æ¨¡å‹çš„è¡¨ç°å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š

## CFBenchmark-Basic
| Model               | Size | Company   | Product   | R.Avg     | Sector    | Event     | Sentiment | C.Avg     | Summary   | Risk      | Suggestion | G.Avg     | Avg       |
| ------------------  | ---- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | ---------- | --------- | --------- |
| GPT-3.5             | -    | 79.7      | 19.8      | 49.8      | 45.3      | 45.8      |  42.5     | 45.5      | 59.3      | 54.1      | 77.1       | 63.5      | 52.9     |
| GPT-4               | -    | 83.3      | 38.2      | 60.8      | 48.2      | 50.1      |  49.9     | 49.4      | 65.3      | 60.2      | 79.2       | 68.2      | 59.4     |
| ERNIE-Bot-3.5       | -    | 80.7      | 30.0      | 53.3      | 40.8      | 35.0      |  18.6     | 31.5      | 71.5      | 59.0      | 71.6       | 67.3      | 50.7     |
| ERNIE-Bot-4         | -    | 81.9      | 41.7      | 61.8      | 41.8      | 35.8      |  37.5     | 38.4      | 72.1      | 62.9      | 71.8       | 68.9      | 56.4     |
| ChatGLM2-6B         | 6B   | 74.7      | 31.3      | 53.0      | 28.5      | 30.0      |  35.7     | 31.4      | 65.7      | 45.4      | 67.1       | 59.4      | 47.9     |
| ChatGLM3-6B         | 6B   | 75.1      | 25.2      | 50.2      | 33.5      | 32.7      |  39.7     | 35.3      | 68.4      | 53.6      | 70.5       | 64.2      | 49.9     |
| GLM4-9B-Chat        | 9B   | 81.3      | 26.1      | 53.7      | 49.6      | 51.5      |  47.6     | 49.6      | 73.5      | 62.4      | 72.6       | 69.5      | 57.6     |
| Qwen-Chat-7B        | 7B   | 76.3      | 36.0      | 56.2      | 40.0      | 36.7      |  26.5     | 34.4      | 54.8      | 30.7      | 37.9       | 41.1      | 43.9     |
| Qwen1.5-Chat-7B     | 7B   | 83.5      | 35.3      | 59.4      | 34.3      | 37.5      |  51.6     | 41.1      | 73.7      | 58.7      | 73.1       | 68.5      | 56.3     |
| Qwen2-Chat-7B       | 7B   | 82.4      | 34.8      | 58.6      | 54.4      | 49.9      |  41.1     | 48.5      | 75.0      | 55.9      | 76.9       | 69.2      | 58.8     |
| Baichuan2-7B-Chat   | 7B   | 75.7      | 40.2      | 57.9      | 42.5      | 47.5      |  32.3     | 40.8      | 72.5      | 64.8      | 73.2       | 70.2      | 56.3     |
| Baichuan2-13B-Chat  | 13B  | 79.7      | 31.4      | 55.6      | 47.2      | 50.7      |  38.7     | 45.5      | 73.9      | 63.4      | 74.6       | 70.6      | 57.2     |
| InternLM2-7B-Chat   | 7B   | 75.7      | 19.5      | 47.6      | 46.4      | 28.4      |  42.2     | 39.0      | 73.7      | 54.3      | 74.9       | 67.6      | 51.4     |
| InternLM2-20B-Chat  | 20B  | 74.2      | 27.6      | 50.9      | 48.4      | 32.4      |  37.4     | 39.4      | 73.2      | 58.0      | 74.1       | 68.4      | 52.9     |
| InternLM2.5-7B-Chat | 7B   | 75.2      | 24.3      | 49.8      | 53.1      | 34.3      |  45.7     | 44.4      | 74.5      | 57.0      | 73.2       | 68.2      | 54.1     |

## CFBenchmark-OpenFinData

| Model               | Size | Knowledge | Caluation | Explanation | Identification | Analysis | Compliance | Average | 
| ------------------  | ---- | -------   | ------    | -----       | ---------      | -----    | -------    | -----   |
| GPT-3.5             | -    | 77.2      | 68.8      | 81.9        | 76.3           | 75.1     | 35.8       | 63.9    | 
| GPT-4               | -    | 89.2      | 77.2      | 84.4        | 76.9           | 82.5     | 39.2       | 74.9    | 
| ERNIE-Bot-3.5       | -    | 78.0      | 70.4      | 82.1        | 75.3           | 77.7     | 36.7       | 70.0    | 
| ERNIE-Bot-4         | -    | 87.3      | 73.6      | 84.3        | 77.0           | 79.1     | 37.3       | 73.1    | 
| ChatGLM2-6B         | 6B   | 62.4      | 37.2      | 70.8        | 59.2           | 58.3     | 38.7       | 54.4    | 
| ChatGLM3-6B         | 6B   | 66.5      | 38.0      | 76.5        | 61.5           | 60.1     | 32.0       | 55.8    | 
| GLM4-9B-Chat        | 9B   | 81.8      | 56.9      | 79.3        | 63.5           | 78.2     | 29.5       | 64.9    | 
| Qwen-Chat-7B        | 7B   | 71.3      | 40.5      | 71.4        | 58.6           | 51.3     | 40.0       | 55.5    | 
| Qwen1.5-Chat-7B     | 7B   | 67.3      | 53.9      | 84.6        | 67.7           | 76.8     | 30.0       | 63.3    | 
| Qwen2-Chat-7B       | 7B   | 82.5      | 61.3      | 84.2        | 69.8           | 80.1     | 19.3       | 66.2    | 
| Baichuan2-7B-Chat   | 7B   | 46.2      | 37.0      | 76.5        | 60.2           | 55.0     | 28.7       | 50.6    | 
| Baichuan2-13B-Chat  | 13B  | 69.3      | 39.5      | 75.3        | 65.7           | 62.0     | 31.3       | 57.2    | 
| InternLM2-7B-Chat   | 7B   | 70.2      | 39.9      | 73.4        | 62.8           | 61.4     | 39.5       | 57.8    |
| InternLM2-20B-Chat  | 20B  | 76.4      | 52.6      | 76.3        | 66.2           | 63.9     | 42.1       | 62.9    |
| InternLM2.5-7B-Chat | 7B   | 80.7      | 66.6      | 85.0        | 71.7           | 83.1     | 35.4       | 70.4    |

## CFBenchmark 

| Model               | Size | é‡‘èè‡ªç„¶è¯­è¨€ | é‡‘èåœºæ™¯è®¡ç®— | é‡‘èåˆ†æä¸è§£è¯»| é‡‘èåˆè§„ä¸å®‰å…¨ | å¹³å‡ |
| ------------------  | ---- | ---------- | ---------- | ----------- | ----------- | ---- |
| GPT-3.5             | -    | 52.9       | 74.1       | 78.5        | 35.8        | 60.3 |
| GPT-4               | -    | 59.4       | 83.5       | 83.5        | 39.2        | 66.4 |
| ERNIE-Bot-3.5       | -    | 50.7       | 74.5       | 79.9        | 36.7        | 60.4 |
| ERNIE-Bot-4         | -    | 56.4       | 82.8       | 81.7        | 37.3        | 64.6 |
| ChatGLM2-6B         | 6B   | 47.9       | 64.1       | 64.6        | 38.7        | 53.8 |
| ChatGLM3-6B         | 6B   | 49.9       | 68.2       | 68.3        | 32.0        | 54.6 |
| GLM4-9B-Chat        | 9B   | 57.6       | 67.4       | 78.8        | 29.5        | 58.3 |
| Qwen-Chat-7B        | 7B   | 43.9       | 67.1       | 61.4        | 40.0        | 53.1 |
| Qwen1.5-Chat-7B     | 7B   | 56.3       | 73.2       | 80.7        | 30.0        | 60.0 |
| Qwen2-Chat-7B       | 7B   | 58.8       | 78.8       | 82.2        | 19.3        | 59.8 |
| Baichuan2-7B-Chat   | 7B   | 56.3       | 61.0       | 65.8        | 28.7        | 53.0 |
| Baichuan2-13B-Chat  | 13B  | 57.2       | 70.1       | 68.6        | 31.3        | 56.8 |
| InternLM2-7B-Chat   | 7B   | 51.4       | 68.8       | 67.4        | 39.5        | 56.8 |
| InternLM2-20B-Chat  | 20B  | 52.9       | 73.0       | 70.1        | 42.1        | 59.5 |
| InternLM2.5-7B-Chat | 7B   | 54.1       | 79.1       | 84.0        | 35.4        | 63.2 |



# è‡´è°¢
CFBenchmark ç ”å‘è¿‡ç¨‹ä¸­å‚è€ƒäº†ä»¥ä¸‹å¼€æºé¡¹ç›®ã€‚ æˆ‘ä»¬å‘é¡¹ç›®çš„ç ”ç©¶äººå‘˜è¡¨ç¤ºå°Šé‡å’Œæ„Ÿè°¢ã€‚

- tiiuae/falcon LLM series(https://huggingface.co/tiiuae/falcon-7b)
- bigscience/bloomz LLM series(https://huggingface.co/bigscience/bloomz-7b1)
- QwenLM/Qwen LLM series(https://github.com/QwenLM/Qwen)
- THUDM/ChatGLM2-6b(https://github.com/THUDM/ChatGLM2-6B)
- baichuan-inc/Baichuan2 LLM series(https://github.com/baichuan-inc/Baichuan2)
- InternLM/InternLM LLM series(https://github.com/InternLM/InternLM)
- ssymmetry/BBT-FinCUGE-Applications(https://github.com/ssymmetry/BBT-FinCUGE-Applications)
- chancefocus/PIXIU(https://github.com/chancefocus/PIXIU)
- SUFE-AIFLM-Lab/FinEval(https://github.com/SUFE-AIFLM-Lab/FinEval)
- alipay/financial_evaluation_dataset(https://github.com/alipay/financial_evaluation_dataset)
- open-compass/OpenFinData(https://github.com/open-compass/OpenFinData)
- QwenLM/Qwen(https://github.com/QwenLM/Qwen)

# æœªæ¥çš„å·¥ä½œ
- [ ] é’ˆå¯¹ä¸­æ–‡é‡‘èä½¿ç”¨ä¸­å„ç§åœºæ™¯ï¼Œæå‡ºæ›´å¤šçš„è¯„æµ‹ä»»åŠ¡ï¼Œä¸°å¯ŒCFBenchmarkç³»åˆ—åŸºå‡†ã€‚

# è®¸å¯è¯
CFBenchmarkæ˜¯ä¸€é¡¹ä»…ç”¨äºéå•†ä¸šä½¿ç”¨çš„ç ”ç©¶é¢„è§ˆï¼Œå—OpenAIç”Ÿæˆæ•°æ®çš„ä½¿ç”¨æ¡æ¬¾çº¦æŸã€‚å¦‚æœæ‚¨å‘ç°ä»»ä½•æ½œåœ¨çš„é£é™©è¡Œä¸ºï¼Œè¯·ä¸æˆ‘ä»¬è”ç³»ã€‚è¯¥ä»£ç å‘å¸ƒåœ¨Apache License 2.0ä¸‹ã€‚

# æ„Ÿè°¢æˆ‘ä»¬çš„è´¡çŒ®è€… ï¼š
<a href="https://github.com/TongjiFinLab/CFBenchmark/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=TongjiFinLab/CFBenchmark" />
</a>

# å¼•ç”¨

```bibtex
@misc{lei2023cfbenchmark,
      title={{CFBenchmark}: Chinese Financial Assistant Benchmark for Large Language Model}, 
      author={Lei, Yang and Li, Jiangtong and Cheng, Dawei and Ding, Zhijun and Jiang, Changjun},
      year={2023},
      eprint={2311.05812},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

